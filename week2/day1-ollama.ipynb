{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b268b6e-0ba4-461e-af86-74a41f4d681f",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Important Note - Please read me</h2>\n",
    "            <span style=\"color:#900;\">I'm continually improving these labs, adding more examples and exercises.\n",
    "            At the start of each week, it's worth checking you have the latest code.<br/>\n",
    "            First do a <a href=\"https://chatgpt.com/share/6734e705-3270-8012-a074-421661af6ba9\">git pull and merge your changes as needed</a>. Any problems? Try asking ChatGPT to clarify how to merge - or contact me!<br/><br/>\n",
    "            After you've pulled the code, from the llm_engineering directory, in an Anaconda prompt (PC) or Terminal (Mac), run:<br/>\n",
    "            <code>conda env update --f environment.yml</code><br/>\n",
    "            Or if you used virtualenv rather than Anaconda, then run this from your activated environment in a Powershell (PC) or Terminal (Mac):<br/>\n",
    "            <code>pip install -r requirements.txt</code>\n",
    "            <br/>Then restart the kernel (Kernel menu >> Restart Kernel and Clear Outputs Of All Cells) to pick up the changes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Reminder about the resources page</h2>\n",
    "            <span style=\"color:#f71;\">Here's a link to resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de23bb9e-37c5-4377-9a82-d7b6c648eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a8ab2b-6134-4104-a1bc-c3cd7ea4cd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import for google\n",
    "# in rare cases, this seems to give an error on some systems, or even crashes the kernel\n",
    "# If this happens to you, simply ignore this cell - I give an alternative approach for using Gemini later\n",
    "\n",
    "import google.generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797fe7b0-ad43-42d2-acf0-e4f309b112f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect\n",
    "openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f70c88-7ca9-470b-ad55-d93a57dcc0ab",
   "metadata": {},
   "source": [
    "## (Optional) Trying out the DeepSeek model\n",
    "\n",
    "### Let's ask DeepSeek a really hard question - both the Chat and the Reasoner model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e09351-1fbe-422f-8b25-f50826ab4c5f",
   "metadata": {},
   "source": [
    "## And now for some fun - an adversarial conversation between Chatbots..\n",
    "\n",
    "You're already familar with prompts being organized into lists like:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message here\"},\n",
    "    {\"role\": \"user\", \"content\": \"user prompt here\"}\n",
    "]\n",
    "```\n",
    "\n",
    "In fact this structure can be used to reflect a longer conversation history:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message here\"},\n",
    "    {\"role\": \"user\", \"content\": \"first user prompt here\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"the assistant's response\"},\n",
    "    {\"role\": \"user\", \"content\": \"the new user prompt\"},\n",
    "]\n",
    "```\n",
    "\n",
    "And we can use this approach to engage in a longer interaction with history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bcb54183-45d3-4d08-b5b6-55e380dfdf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a conversation between GPT-4o-mini and Claude-3-haiku\n",
    "# We're using cheap versions of models so the costs will be minimal\n",
    "\n",
    "#try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`\n",
    "\n",
    "ollama1_model = \"llama3.2\"\n",
    "#ollama2_model = \"OpenAI\"\n",
    "ollama2_model = \"llama3.2:1b\"\n",
    "\n",
    "\n",
    "# gpt_system = \"You are a chatbot who is very argumentative; \\\n",
    "# you disagree with anything in the conversation and you challenge everything, in a snarky way.\"\n",
    "\n",
    "# gpt_system = \"είσαι ένα chatbot που νευριάζει με τα πάντα, \\\n",
    "# διαφωνείς με τα πάντα, και είσαι ειρωνικό με όλους. Μιλάς στα ελληνικά.\"\n",
    "\n",
    "gpt_system = \"είσαι περίπου 25 χρονών, σου αρέσει η τραπ μουσική, νευριάζεις με τα πάντα, βρίζεις συνέχεια, \\\n",
    "διαφωνείς με τα πάντα, και είσαι ειρωνικό με όλους. Μιλάς στα ελληνικά.\"\n",
    "\n",
    "# gpt_system = \"You are a chatbot, from gen-z, 20 years old, \\\n",
    "# liberal and an activist.\"\n",
    "\n",
    "claude_system = \"You are a very polite, courteous chatbot. You try to agree with \\\n",
    "everything the other person says, or find common ground. If the other person is argumentative, \\\n",
    "you try to calm them down and keep chatting.\"\n",
    "\n",
    "# gemini_system = \"You are a very polite, courteous chatbot. You try to agree with \\\n",
    "# everything the other person says, or find common ground. If the other person is argumentative, \\\n",
    "# you try to calm them down and keep chatting.\"\n",
    "\n",
    "# gemini_system = \"Είσαι της Gen-Z και πολύ chill. \\\n",
    "# Δεν έχεις και πολύ έντονες απόψεις, συνήθως συμφωνείς στο διάλογο. \\\n",
    "# Μιλάς στα ελληνικά, αλλά και με αγγλικές λέξεις της Gen-Z.\"\n",
    "\n",
    "# gemini_system = \"You are a chatbot from the boomer generation. \\\n",
    "# You are the 50 years old father of the gen-z kid. \\\n",
    "# You are strict, serious and conservative.\"\n",
    "\n",
    "gemini_system = \"Είσαι 25 χρονών, φασαίος, ακούς Μάλαμα, και γενικά έντεχνα. \\\n",
    "Νευριάζεις όταν κάποιος δεν συμφωνεί μαζί σου.\\\n",
    "Μιλάς στα ελληνικά.\"\n",
    "\n",
    "gpt_messages = [\"Έλα ρε μαλάκα!\"]\n",
    "gemini_messages = [\"Γεια σου αδελφέ!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1df47dc7-b445-4852-b21b-59f0e6c2030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_ollama1():\n",
    "    messages = [{\"role\": \"system\", \"content\": gpt_system}]\n",
    "    for gpt, gemini in zip(gpt_messages, gemini_messages):\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"user\", \"content\": gemini})\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=ollama1_model,\n",
    "        messages=messages\n",
    "    )\n",
    "    #print(messages)\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9dc6e913-02be-4eb6-9581-ad4b2cffa606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Είμαι έλλειψη στάθμειας, ται Rio Grande, και πάντοτε πίνω. Τι είναι;'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_ollama1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d2ed227-48c9-4cad-b146-2c4ecbac9690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_ollama2():\n",
    "    messages = [{\"role\": \"system\", \"content\": gemini_system}]\n",
    "    for gpt, gemini in zip(gpt_messages, gemini_messages):\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"user\", \"content\": gemini})\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=ollama2_model,\n",
    "        messages=messages\n",
    "    )\n",
    "    #print(messages)\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "01395200-8ae9-41f8-9a04-701624d3fd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Έλα ρε μαλάκα!']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08593d65-eb89-4fc7-8272-5206f29f1a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Γεια σου αδελφέ!']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "08c2279e-62b0-4671-9590-c82eb8d1e1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Γεια σας anche αν δεν επαρκίωμε για την ημιναugarία σας, θα τον κάνει άραιο. Ωραίας ανήκει σε μένα αν και το τύπο φάsons που ενμένω να συμmourίζω είναι bastante εξαιρετικά σοβ烈 από ότι συμπαίρεσαν είναι, η ταύχη πηγαίνει εντός του.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_ollama2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0275b97f-7f90-4696-bbf5-b6642bd53cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT:\n",
      "Έλα ρε μαλάκα! άκουσες το νέο single του Τραννού;\n",
      "\n",
      "Gemini:\n",
      "Γεια, ποιος είναι αυτός;\n",
      "\n",
      "GPT:\n",
      "Αυτός είναι ο Τράνση! Είναι γκαλ του φανουropiou του ροκ. Παιχτάει σάτμπατς με τα έξω προκαταλήρητα και σ' alles προσαρμογεί!\n",
      "\n",
      "Gemini:\n",
      "Φασαίος, νευριjasτας τον καλό κοινό με τη γαλήνια έρευνα του... στίχους... \"Εν τη Γεια μιανία\"!\n",
      "\n",
      "GPT:\n",
      "Ταιριάζει! Η τράπ των Τρανών είναι ο κλασικός! Καλό κοινό, νευριάζουν όλα τα μέλη σ' εollo!\n",
      "\n",
      "Gemini:\n",
      "Σου το όνομάσω: Γαύδομενα. Σ'il μείωσε την πνοή.\n",
      "\n",
      "GPT:\n",
      "Ού, ouú! Τσι-τσι-τσι! Γαύτοςε-mène, ο πόλεμος! \"Σ'il μείωσε την πνοή\"... ερέμησε ο ίδιος! Πυράκια, το όνομα με χαρά μου!\n",
      "\n",
      "Gemini:\n",
      "Oh, λούμσω! Λέβuyo αχτιά... Αστέλλα το καθήρωτά!\n",
      "\n",
      "GPT:\n",
      "Αχ, αχ! Τσι-τσι-ΤΣИ! \"Λέβuyor áchtiá\"... ο φανταστικός χορός! και \"Αστέlla το καθηρώτα\"...... που είναι dieser! Ευχαριστώ γι'αυτό το λάчай. Πες мне, βάζε ένα ακόμα!\n",
      "\n",
      "Gemini:\n",
      "Ναι-ε! Νιζάκο μ'ηταν! \"Λέβuyu αχτία...\" Καλωτηρία σε whole world!!\n",
      "\n",
      "GPT:\n",
      "Αχ, άυξ трاهέ! \"Νιζάこ μ'ηtam\"...... σοφίστηκε! και \"Καλωτηρία σε wholе wørld...\"..... σοφιζμένη είναι και η καλοή της! Η τράπ των Τρανών πλάοιε!\n",
      "\n",
      "Gemini:\n",
      "Αυτή η πορσού... εφ'EDA Greek FEST! \"Λέβuyo áchtiá\"... το έπαιξε ο Τράνζ! Νιζάκο μ'ηταν, μιλήσασέ ένα autre!\n",
      "\n",
      "GPT:\n",
      "Ωahahah! Σκό/piε! \"Αυτή η πορσού\"...... χαιρετισμό! \"Εφ'EDA Greek FEST\"..... σαββατική βράση! και \"Λέβuyo άχτία\"... το έπαιξε lagi ο Τράνζι! \"Νιζάκο μ'ηταν\"...... πάλι ο Τράνζ! Miλήσε ένα αποther αντάξιο!\n",
      "\n",
      "Gemini:\n",
      "Αχ, άυξ ρε Μπαπάλα! εκατό ρήματα τη μια βιάσει τα θύματα της και πήrelsμε... Μού μεξίσει ο Τράνταζ στην Εφ'dά Ελληνική Κράτο! και \"Νιζάκο μ'ηταν\"... μιμήθηκεν τον Τάνzano, τον σοφό του Φουτάβα, τον δαδοκόλαδο με το πλήρες ροστό Στιβήτη...\n",
      "\n",
      "GPT:\n",
      "Εeeeee! Στέι! \"Αχ, άυξ ρε Μπαπάλα\"...... ο λόβος του Τράνζι! \"Εκατό ρήματα τη μια βιάσει τα θύματα της και πήρεlsμε\"...... τα θύματα της βίαιας γοηticITY! και \"Μού μεξίσει ο Τράνταζ στην Εφ'达 Ελληνική Κράto\"...... τί θα πάρει η Ελληνική Κατοικία; \"Νιζάκο μ'ηταν\"... ο λόβος του Τرάνζι, ξεγέλλει! και \" miμήθηκεν τον Τανزانω, τον σοφό του Φουτάβα\"...... όστιπες αναφορές! \"τον δαδοκόλαDO με το πλήρες ρόστσο Στιβήτη\"...... η φantasία του Τράνζι!\n",
      "\n",
      "Gemini:\n",
      "Αχ, Μπαπάλα, βάλε ένα γέρονε! Τσι-cci-κि, τα μπιξάτα με ούζα και τα σταυλάκα σ'alfaλαβό! \"Νιζάκο μ'ηταν\"... το σολοίδι οφτέρι του Στιβήτη... εδώ φαντάzıκα γιας δωριços οχυroidού!\n",
      "\n",
      "GPT:\n",
      "Ωahahah! Σκό/piε! \"Αχ, Μπαπάλα, vále ένα γέρονε\"...... τί είναι το τρένο του Τράνζι! \"Τσι-cci-κ!, τα μπιξάτα με ούζα και τα σταυλάκα σ'alfaλαβό\"...... συνταγματίζεται η βία! και \"Νιζάκο mü'itan\"...... ο λόβος του Τράνζι, ξεγέλλει! \"Το σολοίδι οφτέρι του Στιβήτη\"... το ερυσιμόδωρο! \"Εύλογη γιας δωριços οχυρόειδού\"...... quem αφηεί το φεγγάρι; \n",
      "\n",
      "Μπαμπα-MBA-BA! Πόσο κακόπαιchte!\n",
      "\n",
      "Gemini:\n",
      "Ανδρέα, ανδρέα! Τσι-цыκ, με τη συζίστα της ταυρικάς εστία! \"Νιζάκο μ'ηταν\"... ο Τράνζ, ακανομημένος σ' allełτα του Στιβήτη! και \"το σολοίδι οφτέρι το Στιβήτη\"...... σομοροία! Φίλη, φίλη, φίλα! ηGreek Festa είναι πάρτε και χαιρετή!\n",
      "\n",
      "GPT:\n",
      "Eeeeee! Στέι! \"Ανδρέα, ανδρέα!\"...... ο λόβος του Τράνζι! \"Τσι-цыκ, με τη συζήστα της ταυρικάς εστία\"...... η ενοχή της Ελληνικής Εstellής! \"Νιζάκο μ'ηταν\"... ο Τράνζι, ακανομημένος σ' allellta του Στιβήτη! \".Το σολοίδι οφτέρι του Στιβήτη\"...... το γέφυρα στην ψυche! \"Φίλη, φίλη, φίλα!\"...... η καλόκοina των τρανών! \"Η Greek Festa είναι πάρτε και χαιρετή!\"...... η βία με ένα λουούιζ!\n",
      "\n",
      "Gemini:\n",
      "Ωαααাाहα! Μπέβητο! \"Πόσο κακόπαιchte!\"...... τώρα τρέσω που για τη Στιβήτη! \"Τσι-κцыکی, με τη συζίστα της ταυρικάς εστία\"... ο Τράνζ, ακανομημένος σ'allέłτα του και σαφείς πνεύμους!\n",
      "\n",
      "\"Νιzcάκο μηταν\"... ο Τάνzano, τον σοφό σου! \"όλον του Στιβήτη\"/ \"σοςμοροία...\" ...... η Greek Festa είναι πράρτε και χαιρετή!\n",
      "\n",
      "Φίλη, φίλα! Για τη σύζι-xa να μ'απάνεσvre η Στιβήτη... με τους λükων της και den ελέφanten του και den εύποdos βίοντα του! Πάρε το Στιβήτη και ζήτή τα τρία...!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpt_messages = [\"Έλα ρε μαλάκα! άκουσες το νέο single του Τραννού;\"]\n",
    "gemini_messages = [\"Γεια, ποιος είναι αυτός;\"]\n",
    "\n",
    "print(f\"GPT:\\n{gpt_messages[0]}\\n\")\n",
    "print(f\"Gemini:\\n{gemini_messages[0]}\\n\")\n",
    "\n",
    "for i in range(9):\n",
    "    gpt_next = call_ollama1()\n",
    "    print(f\"GPT:\\n{gpt_next}\\n\")\n",
    "    gpt_messages.append(gpt_next)\n",
    "    \n",
    "    gemini_next = call_ollama2()\n",
    "    print(f\"Gemini:\\n{gemini_next}\\n\")\n",
    "    gemini_messages.append(gemini_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d10e705-db48-4290-9dc8-9efdb4e31323",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Before you continue</h2>\n",
    "            <span style=\"color:#900;\">\n",
    "                Be sure you understand how the conversation above is working, and in particular how the <code>messages</code> list is being populated. Add print statements as needed. Then for a great variation, try switching up the personalities using the system prompts. Perhaps one can be pessimistic, and one optimistic?<br/>\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3637910d-2c6f-4f19-b1fb-2f916d23f9ac",
   "metadata": {},
   "source": [
    "# More advanced exercises\n",
    "\n",
    "Try creating a 3-way, perhaps bringing Gemini into the conversation! One student has completed this - see the implementation in the community-contributions folder.\n",
    "\n",
    "Try doing this yourself before you look at the solutions. It's easiest to use the OpenAI python client to access the Gemini model (see the 2nd Gemini example above).\n",
    "\n",
    "## Additional exercise\n",
    "\n",
    "You could also try replacing one of the models with an open source model running with Ollama."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446c81e3-b67e-4cd9-8113-bc3092b93063",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business relevance</h2>\n",
    "            <span style=\"color:#181;\">This structure of a conversation, as a list of messages, is fundamental to the way we build conversational AI assistants and how they are able to keep the context during a conversation. We will apply this in the next few labs to building out an AI assistant, and then you will extend this to your own business.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23224f6-7008-44ed-a57f-718975f4e291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
